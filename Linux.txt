
*Linux* *Bash* 

1. *iconv* 编码转换: 
    $ iconv -f UNICODELITTLE -t MS-ANSI -c resource.h > re.h      ~
    |-f| : 输入编码
    |-t| : 输出编码
    |-c| : 忽略不可转换的字符

2. *xargs* 从标准输入中构造可执行的命令行： 
    build and execute command lines from standard input
    一般形式:
    xargs [-I replace-str] [-n max-args] [command] [initial-arguments]   ~

    |-I| |replace-str|  使用 replace-str 代替输入的参数
    |-n| |max-args|     每次提供的最大参数个数
    |-d| |sep-char|     每个参数的分隔符，当文件内包含空格的时候非常有用，如：`find -name "*.txt" | xargs -d '\n' chmod -x`

    xargs会把标准输入的数据的所有回车去掉.
    当xargs什么参数都不加的时候, 默认把标准输入的参数作为执行命令最尾的参数.

    对xargs内执行多个命令:
         使用sh -c "commands"方式传入多个指令，如：
         $ ls | xargs -n1 -I{} sh -c 'echo -e {} && cat {}' ~

    eg: 
        $ find -type f | xargs -I{} mv {} ./path/       #查找当前目录及子目录的文件,并把这些文件移动到./path/下   ~
        $ find -name '*.[ch]' | xargs grep -E 'define'  #在当前目录下查找c和h文件中出现的'define'的位置           ~
        $ findfile.sh 'uvproj' | xargs -I{} -n1 perl test.pl -f={}  #对findfile输出的结果, 循环调用perl test.pl -f='file' 脚本 ~

3. Bash 常用快捷操作                         *Bash快捷操作*
    |Ctrl+a|   切换到命令行开始
    |Ctrl+e|   切换到命令行末尾
    |Ctrl+l|   清除屏幕内容，效果等同于clear
    |Ctrl+u|   清除剪切光标之前的内容, 并复制到bash自己的剪切板
    |Ctrl+k|   剪切清除光标之后的内容, 并复制到bash自己的剪切板
    |Ctrl+y|   粘贴刚才所删除的字符
    |Ctrl+r|   在历史命令中查找
    |Ctrl+c|   终止命令
    |Ctrl+d|   退出shell，logout
    |Ctrl+z|   转 入后台运行但是当前用户推出将终止。可以在命令前加 nohup 或者在命令后加&
    |history|  显示你所有执行过的编号+历史命令。
    |!125|     执行历史记录中编号为125的命令
    |!!|       重复执行最后一条命令 执行命令后忘记加速度 弥补方法sudo !!
    |!$|       使用上一条命令的最后一个参数;
    |!:n|      使用上一条命令的第n个参数;
    鼠标中键 将当前选中的文本复制到命令行;
    |Shift-insert| 从系统剪切板粘贴

4. 更改linux的命令搜索路径 （设置环境变量）    *linux命令搜索路径*     
    位置：/etc/profile 文件
          PATH的内容就是命令的搜索路径。
    使用Cygwin的时候该命令可能很有用额。。。    

5. 需要执行三个程序，它们是独立的，不需要等待其他命令执行结束。
    解决方案：
    在命令后放一个'&',使得该命令在后台运行。这样你可以用如下的方法同时执行这三个程序。
    $ long &
    $ vim a.cpp &
    $ other &

6. 磁盘使用检测             *Bash磁盘检测*  *du*   *df*
    $ du -a 当前文件夹下所有文件和文件夹使用情况汇总 (disk usage) 
    $ df 磁盘信息
    |du| 详解:
        |--max-depth=N| ：最大目录深度，=1时显示当前目录下所有文件夹大小，=0时显示当前目录大小(等于-s)
        |-s|            : 统计du的参数中目录或文件的容量大小
        |-h|            ：以可读性较好的方式显示大小，MB, GB, KB...
        |-b|, |-k|, |-m|    : 以byte，KB，MB格式显示大小
        |-a|            ：不仅仅显示文件夹的大小, 同时显示所有文件大小

    例子：
        统计当前文件夹下一级子目录和一级文件的容量
        $ du -a --max-depth=1         ~

        遍历目录：
        $ du -a | awk -v IGNORECASE=1 'sub(/^[.0-9A-Z]+\s+/, ""){}; gsub(/ /, "\\ "){}; /\.(h|c)$/' | xargs perl -i $0  ~
        $ find -type f -iregex ""          ~

7. *grep* 使用：
    选项：
    |-R|     ：遍历目录。 同 --recursive
    |-i|     ：忽略大小写
    |-E|     ：使用ERE, 默认使用BRE
    |-n|     ：打印行
    |--color|：高亮显示。可以在.bashrc中加入 alias grep='grep --color -n' 

    eg: 
        $ grep -iR 'find me' *       #在当前目录和子目录下查找find me, 忽略大小写;     ~
        $ grep -E '^[A-Z]?.*$' *.c   #在当前目录下的C文件中查找正则表达式''       ~

8. 当命令行的文件参数为 '-' 时表示从标准输入获取数据      *Bash标准输入*
    eg: grep -iR 'the girl' * | gvim -        #使用gvim编辑grep获得的数据         ~
    Note 注意以下两种用法的区别:
        a. $ history           | grep 'find_data' -       # 对history输出的内容进行搜索~
        b. $ findfile.sh 'c|h' | xargs grep 'find_data'   # 对findfile.sh输出的每个文件里的内容进行搜索~

9. *sort* 使用
    默认:
    不忽略行头的空白, ASCII码升序, 域分割符空格, 行开始
    
    选项:
    |-n| {--numric-sort} 根据数字的大小排序
    |-r| {--reverse} 降序排序, 默认是升序
    |-b| {--ignore-leading-blanks} 忽略行头的空白
    |-f| {--ignore-case} 忽略大小写

    |-c| {--check} 检查文件是否已经排好序
    |-M| {--month-sort} 按月份排序 eg: (unknown) < 'JAN' < ... < 'DEC'
    |-h| {--human-numeric-sort} 用可读的数字比较 eg: 2k, 1G
    |-u| {--unique} 去掉重复行

    |-k| {--key} 通过key指定的域进行排序
    |-t| {--field-separator} 指定域分割符; 默认是: 空格
    
    关于 |-k| |-t| 选项的说明(精简):
        1>. syntax : -t |Separator| -k |FieldStart||*.CharStart* Modifier
            eg     : -t   ';'     -k     1     .    2     fr
            explain: 使用;作为域分隔符, 从第1个域的第2个字符开始进行忽略大小写的降序排序
        2>. 关于'域': 
            a. 默认域分割符是空格;
            b. 如文件中某行数据为 'abc 123 efg' 则: 'abc'是第1个域; '123'是第2个域 'efg'是第3个域

    eg: 
        $sort -t ';' -k 1.2fr file.txt   #使用;作为域分隔符, 从第1个域的第2个字符开始进行忽略大小写的降序排序   ~
        $sort -nb file.txt               #忽略行头的空白, 以行开始的数字大小对文件进行排序      ~

10. 常用文件操作命令
    a. 创建文件夹 *mkdir*
        mkdir DIR...
    b. 创建文件 *touch* 
        touch FILE...
        gvim FILE...
        >FILE...
    c.删除文件或文件夹 *rm* 
        rm  FILE...
        rm -r DIR...
        |-i| 删除文件前需要用户(y/n)确认
    d.拷贝文件或文件夹 *cp*
        cp SOURCE_FILE DEST_FILE
        cp SOURCE_FILE... DEST_DIR
        cp -r SOURCE_DIR... DEST_DIR  #如果DEST_DIR不存在则创建
    e.移动文件或文件夹 *mv*
        mv SOURCE_FILE DEST_FILE
        mv SOURCE_FILE... DEST_DIR
        mv SOURCE_DIR... DEST_DIR 
    f.查看文件 *cat* *less* *more*
        cat FILE...
        less FILE...
        more FILE...

11. Shell 科学计算器
    语法: printf "%d" $((...)) 或 echo $((...))
          其中, $(( )) 是用来作整数运算的, "..."为计算表达式, "%d"为结果展示方式

    算术运算符:
        - +        单目负号和正号
        ! ~        逻辑取反，按位取反
        **         指数
        * / %      乘，除，求余
        + -        加，减
        << >>      按位左移，按位右移
        <= >= < >  比较
        == !=      相等，不等
        &          按位与
        ^          按位异或
        |          按位或
        &&         逻辑与
        ||         逻辑或

    进制转换: 
        输入进制: ([base#]n)
            0xXX : 16进制 同16#XX
            XX   : 10进制 同10#XX
            0XX  : 8 进制 同8#XX
            2#XX : 2 进制
            24#XX: 24进制
        输出进制: printf的 %d %x

    中间值记忆:
        记录: n=$((...))   # "="左右不能有空格
        使用: $(($n * 10))

12. *xxd* 十六进制dump工具 使用

    |-b|  二进制显示, 默认十六进制

    |-c| {n}  每行显示多少字节, 默认16. 例如: -c32 (每行显示32字节)
    |-g| {n}  每组包含多少字节, 默认2. 例如: -g4 (每组包含4字节)

    |-s| {[+][-]seek}  dump的开始位置, 默认是开头. +:从开头算 -:从末尾算
    |-l| {len}         从开始位置dump的长度, 默认是所有.

    |-u|  输出[a-z]大写, 默认小写

    |-ps| 以 "intel hex file format" 显示
    |-i|  以C语言{include}数组格式显示

    |-r|  还原

    例子:
        1 以4个byte为一组, 并且把每组数据的字节序翻转, 12345678 => 78563412
           $ xxd -g4 "file.bin" | sed 's/ \([0-9a-f]\{2\}\)\([0-9a-f]\{2\}\)\([0-9a-f]\{2\}\)\([0-9a-f]\{2\}\)/ \4\3\2\1/g'   ~

        2 Create a 65537 byte file with all bytes 0x00, except for the last one which is 'A' (hex 0x41).
           $ echo "010000: 41" | xxd -r > file  ~

        3 Print 3 lines (hex 0x30 bytes) from the end of file.
           $ xxd -s -0x30 file ~

        4 Hexdump the first 120 bytes, with 12 octets per line, 4 octets per group.
           $ xxd -l120 -c12 -g4 file.bin  ~
            >
             0000000: e8440010 c1000010 cf000010  .D..........
             000000c: d1000010 d3000010 d5000010  ............
             0000018: d7000010 00000000 00000000  ............
             0000024: 00000000 00000000 d9000010  ............
             0000030: db000010 00000000 dd000010  ............
             000003c: df000010 11050010 e1000010  ............
             0000048: e1000010 25040010 e1000010  ....%.......
             0000054: 45050010 e1000010 e1000010  E...........
             0000060: e1000010 00000000 55070010  ........U...
             000006c: f1060010 e1000010 e1000010  ............
<

13. ln 创建链接
    ln [option] source_file dist_file 
    |-f| 建立时，将同档案名删除.
    |-s| 建立的软连接

    eg:
        1、ln -s abc cde 建立abc的软连接->cde
        2、ln abc cde    建立abc的硬连接->cde

    软链接与硬链接的区别:
    硬链接可认为是一个文件拥有两个文件名, 当前目录为硬链接文件所在的目录
    而软链接则是系统新建一个链接文件, 此文件指向其所要指的文件, 当前目录为所指文件的目录。

14. 补丁 diff和patch
    制作补丁文件: >
    diff -urN dir_a/ dir_b/ >c.patch   # dir_a是原始文件夹，dir_b是修改后的文件夹，C称为dir_a的补丁文件。
<    打补丁: >
    patch -p1 dir_a/ <c.patch           # 应用c.patch到dir_a，使dir_a成为dir_b

15. 压缩
    .tar 
    解包：tar xvf FileName.tar
    打包：tar cvf FileName.tar DirName
    （注：tar是打包，不是压缩！）
    ———————————————
    .gz
    解压1：gunzip FileName.gz
    解压2：gzip -d FileName.gz
    压缩：gzip FileName

    .tar.gz 和 .tgz
    解压：tar zxvf FileName.tar.gz
    压缩：tar zcvf FileName.tar.gz DirName
    ———————————————
    .bz2
    解压1：bzip2 -d FileName.bz2
    解压2：bunzip2 FileName.bz2
    压缩： bzip2 -z FileName

    .tar.bz2
    解压：tar jxvf FileName.tar.bz2
    压缩：tar jcvf FileName.tar.bz2 DirName
    ———————————————
    .bz
    解压1：bzip2 -d FileName.bz
    解压2：bunzip2 FileName.bz
    压缩：未知

    .tar.bz
    解压：tar jxvf FileName.tar.bz
    压缩：未知
    ———————————————
    .Z
    解压：uncompress FileName.Z
    压缩：compress FileName
    .tar.Z

    解压：tar Zxvf FileName.tar.Z
    压缩：tar Zcvf FileName.tar.Z DirName
    ———————————————
    .zip
    解压：unzip FileName.zip
    压缩：zip FileName.zip DirName
    ———————————————
    .rar
    解压：rar x FileName.rar
    压缩：rar a FileName.rar DirName
    ———————————————
    .lha
    解压：lha -e FileName.lha
    压缩：lha -a FileName.lha FileName
    ———————————————
    .rpm
    解包：rpm2cpio FileName.rpm | cpio -div
    ———————————————
    .deb
    解包：ar p FileName.deb data.tar.gz | tar zxf -
    ———————————————
    .tar .tgz .tar.gz .tar.Z .tar.bz .tar.bz2 .zip .cpio .rpm .deb .slp .arj .rar .ace .lha .lzh .lzx .lzs .arc .sda .sfx .lnx .zoo .cab .kar .cpt .pit .sit .sea
    解压：sEx x FileName.*
    压缩：sEx a FileName.* FileName

16. AWK

    awk处理的单位为行(record), 即对每一行调用处理操作. 

    基本命令格式为：
        Patterns and Actions
        AWK是一种基于行的语言。
        语言格式是：
            patterns{actions} 即：先patterns后大括号action; ~
            解释：模式成功则执行{}内的actions;
        1、有patterns, 无actions，则默认action为 ：{print}
        2、无patterns, 有actions，则默认patterns一定匹配该行
        actions 可以包括各种函数和逻辑控制语言。
        Patterns包括的内容在下面

        Patterns包括：
            BEGIN                          :所有操作的开始
            END                            :所有操作的结束
            BEGINFILE                      :当前文件的开始
            ENDFILE                        :当前文件的结束
            /regular expression/           :正在表达式
            relational expression          :关系运算
            pattern && pattern || pattern  :逻辑运算符
            pattern ? pattern : pattern    ：
            (pattern)                      ：
            ! pattern                      ：
            pattern1, pattern2             ：

        逻辑控制：
            if (condition) statement [ else statement ]
            while (condition) statement
            do statement while (condition)
            for (expr1; expr2; expr3) statement
            for (var in array) statement
            break
            continue
            delete array[index]
            delete array
            exit [ expression ]
            { statements }
            switch (expression) {
            case value|regex : statement
            ...
            [ default: statement ]
            }

    常用内嵌函数：*sub* *gsub*
        大部分C库函数可以使用

        替换第一个：sub(/regexp/, replacement [, target])
        全局替换  ：gsub(/regexp/, replacement [, target])
        长度      ：length([string])
        变小写    ：tolower(string)
        变大写    ：toupper(string)

    内建变量
        $0       当前记录（这个变量中存放着整个行的内容）
        $1~$n    当前记录的第n个字段，字段间由FS分隔

        FS       输入字段分隔符 默认是空格 field separator
        RS       输入的记录分隔符， 默认为换行符\n record separator

        OFS      输出字段分隔符， 默认也是空格 
        ORS      输出的记录分隔符，默认为换行符

        NF       当前记录中的字段个数，就是有多少列。number of fields
        NR       已经读出的记录数，就是行号，从1开始，如果有多个文件话，这个值也是不断累加中。 number of records
        FNR      当前记录数，与NR不同的是，这个值会是各个文件自己的行号

        FILENAME 当前输入文件的名字

        IGNORECASE=1 忽略大小写

    常用选项：
        -v ：-var 设置变量值，就像在BEGIN{}中定义的一样 eg: $ awk -v FS='-' 'print $1' a.txt
        -f ：使用awk脚本文件。eg: $ awk -f script.awk a.txt

    在shell中单引号和双引号的区别。(都表示字符串)
        双引号: 内部的 \what、 $x、`what 会被shell解析成为其他的值。
        单引号: 内部的值不会被shell解析。
        所以在使用awk时候一定要使用单引号

    使用例子：
        格式化输出 >
        $ awk '{print $1, $4}' netstat.txt
        $ awk '{printf "%-8s %-8s %-8s %-18s %-22s %-15s\n",$1,$2,$3,$4,$5,$6}' netstat.txt
<
        使用比较运算符 >
        $ awk '$6=="LISTEN" || $3>0 || NR==1' netstat.txt
<
        使用正则表达式 >
        $ awk '/LISTEN/' netstat.txt
        $ awk '!/LISTEN/' netstat.txt
        $ awk '$6 ~ /TIME/ || NR==1 {print NR}' netstat.txt
        $ awk '$6 !~ /WAIT/ || NR==1 {print NR}' netstat.txt
<
        使用BEGIN 和 END >
        $ awk 'BEGIN{FS=":"} {print $1, $2}' OFS="-" a.txt
        $ awk '{sum+=$5} END {print sum}' netstat.txt
<
        for的使用 >
        $ awk '{for(i=1;i<=NF;i++)printf("%dx%d=%d%s", i, NR, i*NR, i==NR?"\n":"\t")}' a.txt
        $ awk 'NR!=1{a[$6]++;} END {for (i in a) print i ", " a[i];}' netstat.txt
<
        替换(sub & gsub)： >
        $ du -a | awk -v IGNORECASE=1 'sub(/^[.0-9A-Z]+\s+/, ""){}; gsub(/ /, "\\ "){}; /\.((h)|(c))/' | xargs perl -i $0
<
        使用脚本文件 >
        $ awk -f cal.awk score.txt
        $ cat cal.awk
            #运行前
            BEGIN {
                math = 0
                english = 0
                computer = 0
                printf "NAME    NO.   MATH  ENGLISH  COMPUTER   TOTAL\n"
                printf "---------------------------------------------\n"
            }
            #运行中
            {
                math+=$3
                english+=$4
                computer+=$5
                printf "%-6s %-6s %4d %8d %8d %8d\n", $1, $2, $3,$4,$5, $3+$4+$5
            }
            #运行后
            END {
                printf "---------------------------------------------\n"
                printf "  TOTAL:%10d %8d %8d \n", math, english, computer
                printf "AVERAGE:%10.2f %8.2f %8.2f\n", math/NR, english/NR, computer/NR
            }
<
    字符串连接
        直接写在一起即可: str = "0x"value; #value是一个变量

    进制转换
        10进制 -> 16进制: nHex = sprintf("0x%X", nDec);
        16进制 -> 10进制: nDec = strtonum("0x"nHex);

    位操作
        与      : and(v1,v2)
        或      : or (v1,v2)
        异或    : xor(v1,v2)
        左移    : lshift(val,count)
        右移    : rshift(val,count)
        按位取反: compl(val)

17. SED (Stream EDitor)
    SED是一种基于行的语言。

    基本格式为：
        语言格式是：
            patterns{cmd} ~
            解释：模式成功则执行{}内的cmd;
            无patterns, 有cmd，则对所有行进行处理
            默认情况，sed会把操作的结果打印到标准输出

        patterns：
            /regex/             :正在表达式
            pattern1, pattern2  :从pattern1到pattern2
            pattern, +5         :从pattern1到+5行
            pattern!            :没有匹配到pattern
            10                  :第10行

        cmd：
            s/m/a/g             :替换：把m替换成a
            a                   :append，匹配行后添加行
            i                   :insert，匹配行前插入行
            c                   :change，替换掉匹配的行
            d                   :delete，删除匹配行
            p                   :print， 匹配行 (该行可能会导致打印两边，因为默认会打印该行的)
            N                   :next，  把下一行附加到当前行进行处理
            n                   :next，  处理下一行
            q                   :quit，  退出

        控制：
            cmd1; cmd2          :将多条命令串联起来
            {cmds}              :命令打包

        常用命令行选项：
            -i                  :直接对文件进行操作，(默认将sed的结果打印到标准输出)
            -n                  :不自动打印sed的结果，只打印使用p命令的结果

    例子： >
        $ sed "s/my/your/g" pets.txt                 # s     替换所有的my为your
        $ sed -i "s/my/Hao/g" pets.txt               # s -i  直接修改文件内容
        $ sed 's/^/#/g' pets.txt                     # s     在行首加入#
        $ sed 's/<[^>]*>//g' html.txt                # s     删除html标记
        $ sed "3s/my/your/g" pets.txt                # s     仅把第3行的my替换成your
        $ sed "3,6s/my/your/g" pets.txt              # s     把第3行到第6行的my替换成your
        $ sed 's/s/S/1' my.txt                       # s     仅替换第1个s为S
        $ sed 's/s/S/3g' my.txt                      # s     替换第3个和之后的s为S
        $ sed 's/my/your/g; s/This/That/g' my.txt    # s     先替换my为your，再替换所有的This为That
        $ sed 's/my/[&]/g' my.txt                    # s &   替换所有的my为[my], &表示匹配到的内容
        $ sed '/dog/,+3s/^/# /g' pets.txt            # s +3  对匹配上dog的行和之后的3行执行替换
        $ sed 'N;N;s/my/your/' pets.txt              # N     将下一行和下下行纳入当前行执行s/my/your/
        $ sed '/my/{n;d}' pets.txt                   # n     删除匹配上my的下一行
        $ sed "1 i This is" my.txt                   # i     在第一行前插入This is
        $ sed "$ a This is" my.txt                   # a     在最一行后插入This is
        $ sed "/fish/a This is" my.txt               # a     匹配到fish的行后插入This is
        $ sed "2 c This is" my.txt                   # c     第二行替换成This is
        $ sed "/fish/c This is" my.txt               # c     匹配到fish的行替换成This is
        $ sed '/fish/d' my.txt                       # d     删除匹配带fish的行
        $ sed '2d' my.txt                            # d     删除第2行
        $ sed '2,$d' my.txt                          # d     删除第2行到最后一行
        $ sed '/fish/p' my.txt                       # p     重复打印匹配到fish的行
        $ sed -n '/fish/p' my.txt                    # p -n  仅打印match的行
        $ sed -n 's/fish/dog/p' my.txt               # p -n  仅打印match的行
        $ sed -n '/dog/,/fish/p' my.txt              # p -n  仅打印匹配上dog的行一直到匹配上fish行
        $ sed -n '1,/fish/p' my.txt                  # p -n  仅打印第一行到匹配上fish的上
        $ sed '3,6 {/This/d}' pets.txt               # {}    对第3行到第6行执行：删除匹配到This的行
        $ sed '3,6 {/This/{/fish/d}}' pets.txt       # {}    对第3行到第6行且对匹配上This的行执行：删除匹配到fish的行
        $ sed '1,${/This/d;s/That/This/g}' pets.txt  # {}    对第1行到最后一行执行：删除所有匹配到This的行，然后替换所有That为This

18. 几种POSIX流派的regex说明 >
    +---------------------------------------------------------------------------+
    | 流派      说明                                        工具                |
    | BRE       (、)、{、}必须转义，不支持+、?、|           grep、sed、vi、more | #vi有些不一样
    | GNU BRE   (、)、{、}、+、?、|必须转义                 GNU grep、GNU sed   |
    | ERE       (、)、{、}、+、?、|直接使用, \1、\2不确定   egrep、awk          |
    | GNU ERE   (、)、{、}、+、?、|直接使用, 支持\1、\2     grep –E、GNU awk    |
    +---------------------------------------------------------------------------+
    | BRE ERE 共同支持的元字符有: \.*^$[]                                       |
    +---------------------------------------------------------------------------+
<
    常用Linux/Unix工具中regex的表示法 >
    +---------------------------------------------------------------+
    | Perl        awk       grep -E   grep       sed        vi/vim  |
    | \.*^$[]     ...       ...       ...        ...        ...     |
    | +           +         +         \+         \+         \+      |
    | ?           ?         ?         \?         \?         \=      |
    | {m,n}       {m,n}     {m,n}     \{m,n\}    \{m,n\}    \{m,n}  |
    | \b          \< \>     \< \>     \< \>      \< \>      \< \>   |
    | |           |         |         \|         \|         \|      |
    | (…)         (…)       (…)       \(…\)      \(…)       \(…\)   |
    | \1 \2       不支持    \1 \2     \1 \2      \1 \2      \1 \2   |
    | (?=atom)                                              atom\@= |
    | (?!atom)                                              atom\@! |
    +---------------------------------------------------------------+

19. linux用户、组、权限

    用户组： ~
    u (user)：   拥有者
    g (group)：  拥有者所在的组
    o (others)： 其他组
    a (all)：    所有用户

    一般权限： ~
    r (Read)：    文件：具有读取文件内容的权限
                  目录：具有浏览目录的权
    w (Write)：   文件：具有新增、修改文件内容的权限
                  目录：具有删除、移动目录内文件的权限
    x (eXecute)： 文件：具有执行文件的权限
                  目录：该用户具有进入目录的权限

    特殊权限：(出现在相应域的可执行位上) ~
    s (SUID,Set UID)：   仅作用于"拥有者域"
                         文件：常作用于可执行文件。任意执行该文件的"使用者"都将获得"拥有者"的特权，如"/bin/passwd"命令就是如此
                         目录：
    s (SGID,Set GID)：   仅作用于"拥有者所在组域"
                         文件：常作用于可执行文件。任意执行该文件的"使用者"都将获得"拥有者所在的组"的特权
                         目录："使用者"在该目录创建的所有文件都获得"拥有者所在组"的特权
    t (SBIT,Sticky Bit)：仅作用于"其他组域"
                         文件：不可以作用于文件
                         目录："使用者"在该目录创建的文件只有该用户自己和ROOT可以修改，其他用户无权修改，如"/tmp"目录

    用户和组的文件路径： ~
    用户：      $UID, /etc/passwd
    组：        $GID, /etc/group
    用户口令：  /etc/shadow
    组口令：    /etc/gshadow

    用户管理命令: ~
    useradd:    添加用户
    userdel:    删除用户
    usermod:    修改用户帐号属性
    id:         查看用户的帐号属性信息
    finger:     查看用户帐号信息
    chsh:       修改用户的默认shell
    chfn:       修改注释信息
    passwd:     密码管理
    pwck:       检查用户帐号完整性

    组管理命令: ~
    groupadd:   创建组
    groupdel:   删除组
    groupmod:   修改组属性
    gpasswd：   为组设定密码
    newgrp：
    chage：     更改密码使用时间

    权限管理: ~
    chown:      改变文件的拥有者(只有管理员可以使用此命令)
    chgrp:      改变文件的拥有者的组
    chmod:      修改文件的权限
    umask:      设置默认权限的掩码。

    chmod命令: ~
        chmod [OPTION]... MODE[,MODE]... FILE...
        chmod [OPTION]... OCTAL-MODE FILE...
        MODE:
            可读式表示:
                格式为: who opcode permission
                who:
                    u 用户
                    g 组
                    o 其它
                    a 所有用户(默认)
                opcode:
                    + 增加权限
                    - 删除权限
                    = 重新分配权限 
                permission:
                    r 读
                    w 写
                    x 执行
                    s SUID SGID
                    t SBIT
            八进制表示:
                三个数字： User Group Other
                四个数字： Spacial User Group Other >
                ------------------------------
                Spacial - User - Group - Other
                SBIT:1    x:1    x:1     x:1
                SGID:2    w:2    w:2     w:2
                SUID:4    r:4    r:4     r:4
<        例子: >
        $ chmod u+x file             # 给file的属主增加执行权限
        $ chmod 751 file             # 给file的属主分配读、写、执行(7)的权限，给file的所在组分配读、执行(5)的权限，给其他用户分配执行(1)的权限
        $ chmod u=rwx,g=rx,o=x file  # 上例的另一种形式
        $ chmod =r file              # 为所有用户分配读权限
        $ chmod 444 file             # 同上例
        $ chmod a-wx,a+r   file   　 # 同上例
        $ chmod -R u+r directory     # 递归地给directory目录下所有文件和子目录的属主分配读的权限
        $ chmod 4755                 # 设置GUID，给属主分配读、写和执行权限，给组和其他用户分配读、执行的权限。
<
    umask命令： ~
        umask设置了用户创建文件的默认权限，它与chmod的效果刚好相反，umask设置的是权限“补码”，而chmod设置的是文件权限码。
        一般在/etc/profile、$ [HOME]/.bash_profile或$[HOME]/.profile中设置umask值。
        默认情况下的umask值是022(可以用umask命令查看）， 此时你建立的文件默认权限是644(666-022)，建立的目录的默认权限是755(777-022)
        例子： >
        $ umask         # 读取当前文件夹的umask值
        $ umask 077     # 默认当前文件夹创建文件的权限是600，创建目录的权限是700
<
    ls -l 解析： ~
    内容如下： >
    -rwxrw-r‐-1 root root 1213 Feb 2 09:39 abc
<    - 第一个字符代表文件(-)、目录(d)，链接(l)
    - 其余字符每三个一组(rwx)，读(r)、写(w)、执行(x)、特殊(s,s,t)
        第一组rwx：文件所有者的权限是读、写和执行
        第二组rw-：与文件所有者同一组的用户的权限是读、写但不能执行
        第三组r--：不与文件所有者同组的其他用户的权限是读不能写和执行
    - 1 表示连接的文件数
    - root 表示用户
    - root 表示用户所在的组
    - 1213 表示文件大小
    - Feb 2 09:39 表示最后修改日期
    - abc 表示文件名

20. 远程登录与拷贝
    远程登录：
    - telnet
    - ssh
    远程拷贝：
    - scp: 使用ssh协议进行远程拷贝
    - rsync: 既可以使用rsync协议也可以使用ssh协议
             使用ssh协议指定端口：rsync -rvz --progress -e 'ssh -p 22'

21. 使用cygwin的ssh服务器
    1、配置cygwin
        需要的软件包：cygrunsrv、openssh ~
        管理员身份运行cygwin
        $ ssh-host-config               #引导ssh服务配置 ~
>
        *** Query: Should StrictModes be used? (yes/no)                         #输入yes
        *** Query: Should privilege separation be used? (yes/no)                #输入yes
        *** Query: Do you want to install sshd as a service?
        *** Query: (Say "no" if it is already installed as a service) (yes/no)  #输入yes
        *** Query: Enter the value of CYGWIN for the daemon: []                 #输入ntsec
        *** Info: This script plans to use 'cyg_server'.
        *** Info: 'cyg_server' will only be used by registered services.
        *** Query: Do you want to use a different name? (yes/no)                #输入no
        *** Query: Please enter the password for user 'cyg_server':             #输入密码
        *** Query: Create new privileged user account 'PC\cyg_server'
                   (Cygwin name: 'cyg_server')? (yes/no)                        #输入yes
        *** Query: Reenter:                                                     #输入密码
        *** Info: The sshd service has been installed under the 'cyg_server'
        *** Info: account.  To start the service now, call `net start sshd' or
        *** Info: `cygrunsrv -S sshd'.  Otherwise, it will start automatically
        *** Info: after the next reboot.
        *** Info: Host configuration finished. Have fun!
<
        $ net start sshd                #启动SSH服务~
        $ mkpasswd -l > /etc/passwd     #使用windows用户的密码 ~
        $ mkgroup -l > /etc/group       #使用windows用户组 ~
        NOTE: 可以在windows服务里找到"CYGWIN sshd"的服务
        NOTE: /etc/sshd_config 内包含sshd的详细配置（可修改默认端口号等），修改后重启ssh服务
        NOTE: ~/.ssh/config 内包含客户端的配置
        NOTE: 别的有用的命令：
              `$ net stop sshd  #关闭服务，用于重启`
              `$ sc delete sshd #删除服务，用于重装`
    2、开放windows的22端口 (SSH使用端口)
       防火墙中设置允许22端口入栈, window防火墙为例： >
       入栈规则->新建规则->规则类型(选择"端口")->TCP,22->允许连接
<    3、客户端远程操作： >
       $ ssh server@192.168.1.123  #使用服务器端的用户名密码
<    4、客户端不用每次都再输入密码 (密钥认证)： >
       $ ssh-keygen                        #创建密码，一路回车
       $ ssh-copy-id server@192.168.1.123  #拷贝密码到服务器 或者拷贝客户端的id_rsa.pub文件的内容到服务器的.ssh/authorized_keys内
       NOTE: 确保服务器的 ~/.ssh的权限是700，~/.ssh/authorized_keys的权限是600
<    5、查看或踢出已经登录的用户： >
       $ sudo w -f            #查看登录用户
       $ pkill -kill -t pts1  #踢出登录用户，或者 $ pkill -9 -t pts1 强制踢出

22. 使用ssh正向连接、反向连接、做socks代理的方法

    用ssh做正向连接 (LocalForward) ~
    说明： client连上server，然后把server能访问的机器地址和端口（当然也包括server自己）镜像到client的端口上。
    命令： `$ ssh -L [客户端IP或省略:][客户端端口]:[服务器侧能访问的IP:][服务器侧能访问的IP的端口] 登陆服务器的用户名@服务器IP -p [服务器ssh服务端口(默认22)]`
           其中，客户端IP可以省略，省略的话就是127.0.0.1了，也就是说只能在客户端本地访问。服务器IP都可以用域名来代替。
    举例： >
           你的IP是192.168.1.2，你可以ssh到某台服务器8.8.8.8，8.8.8.8可以访问8.8.4.4，你内网里还有一台机器可以访问你。
           如果你想让内网里的另外一台电脑访问8.8.4.4的80端口的http服务，那么可以执行：
           ssh -L 192.168.1.2:8080:8.8.4.4:80 test@8.8.8.8 (config: `LocalForward: 192.168.1.2:8080 8.8.4.4:80`)
           也就是说，ssh到8.8.8.8上，然后让8.8.8.8把8.8.4.4的80端口映射到本地的8080端口上，而且和本地192.168.1.2这个IP绑定。
           内网里的另外一台机器可以通过IE浏览器中输入http://192.168.1.2:8080查看8.8.4.4的网页。
           当然，如果是其他服务，比如ftp、ssh、远程桌面也是可以的。不过，VPN貌似是不行的，可能是因为GRE协议无法通过。
<
    用ssh做反向连接 (RemoteForward) ~
    说明： client连上server，然后把client能访问的机器地址和端口（也包括client自己）镜像到server的端口上。
           反向连接用得可能更多一些。比如你的客户端在内网，在外网是无法直接访问到的，这时用反向连接打通一条隧道，就可以从外网通过这条隧道进来了。
    命令： `$ ssh -R [服务器IP或省略:][服务器端口]:[客户端侧能访问的IP:][客户端侧能访问的IP的端口] 登陆服务器的用户名@服务器IP -p [服务器ssh服务端口(默认22)]`
           其中，服务器IP如果省略，则默认为127.0.0.1，只有服务器自身可以访问。指定服务器外网IP的话，任何人都可以通过[服务器IP:端口]来访问服务。
           当然，这个时候服务器本机也要输入外网IP:端口来访问。
    举例： >
           你的IP是192.168.1.2，你可以ssh到外网某台服务器8.8.8.8，你内网里有一台机器192.168.1.3。
           如果你想让外网所有的能访问8.8.8.8的IP都能访问192.168.1.3的http服务，那么可以执行：
           ssh -R 8.8.8.8:8080:192.168.1.3:80 test@8.8.8.8 (config: `RemoteForward: 8.8.8.8:8080 192.168.1.3:80`)
           也就是说，ssh到8.8.8.8上，然后把本地局域网内192.168.1.3的80端口映射到8.8.8.8的8080端口上，
           这样外网任何一台可以访问8.8.8.8的机器都可以通过8080端口访问到内网192.168.1.3机器的80端口了。
           反向连接同样支持各种服务。
<
    用ssh做socks代理 (正向:DynamicForward, 反向:RemoteForward) ~
    说明： 假设你内网里某台机器可以上网，但是你不能上网，如果你有ssh到那台机器的权限，那么就可以利用ssh方式建立一个代理socks5，通过代理来上网。
    命令： `$ ssh -D [本地IP或省略:][本地端口] 登陆服务器的用户名@服务器IP -p [服务器ssh服务端口(默认22)]`
           道理和上面是一样的，执行这个命令之后，本地会监听指定的端口等待连接。
           在配置代理的时候直接选择Sock5就可以了，不需要用户名和密码验证。
           windows系统代理配置方法：Internet选项->连接->局域网设置：勾选为LAN使用代理服务器，然后任何字段都不要填，点“高级”按钮，在套接字里面填好相应的配置，其他都留空。
           一个叫做Sockscap的软件，把应用扔进去就能以代理的方式上网了。
           如果你想把socks代理转换成http代理，可以用privoxy这个东东。
    举例： >
           正向：ssh -D 1234 test@8.8.8.8 (config: `DynamicForward: 1234`)
           反向：ssh -R 1234 test@8.8.8.8 (config: `RemoteForward: 1234`)


23. tmux
    架构:
        ┌Server
        │   ┌Session1
        │   │   ┌Window1
        │   │   │   ┌Pane1
        │   │   │   ├Pane2
        │   │   │   ├Pane3
        │   │   │   └···
        │   │   ├Window2
        │   │   ├Window3
        │   │   └···
        │   ├Session2
        │   ├Session3
        └   └···

        启动一个tmux之后就会自动启动一个Server (当Server下没有任何Session后，该Server就会退出，也可以通过：`tmux kill-server`退出)，
        这个Server下可以有很多个Session(会话/工作台，通过：`tmux new`创建， `tmux ls`列出，`tmux atach -t xxx`进入，`tmux detach`挂起，`tmux kill-session -t xxx`退出)，
        每个Session下又可以有很多个window(窗口)，
        每个window下又可以有很多pane(子窗口/小窗口)

    注意：
        1、启动tmux server是很慢的，所以别总是直接退出session(退出shell(Ctrl-D)也会直接退出session的)，常用`tmux detach`和`tmux atach`
        2、使用tmuxinator时，最好tmux server已经启动了，否则启动tmuxinator非常慢
        3、tmuxinator的自定义layout可以在已经手动layout之后使用 `tmux list-windows` 显示，pane编号使用 `Ctrl-b q` 显示

    快捷键: >
                    Ctrl+b      激活控制台；此时以下按键生效
        系统操作    ?           列出所有快捷键；按q返回
                    d           脱离当前会话；这样可以暂时返回Shell界面，输入tmux attach能够重新进入之前的会话
                    D           选择要脱离的会话；在同时开启了多个会话时使用
                    Ctrl+z      挂起当前会话
                    r           强制重绘未脱离的会话
                    s           选择并切换会话；在同时开启了多个会话时使用
                    :           进入命令行模式；此时可以输入支持的命令，例如kill-server可以关闭服务器
                    [           进入复制模式；此时的操作与vi/emacs相同，按q/Esc退出
                    ~           列出提示信息缓存；其中包含了之前tmux返回的各种提示信息
        窗口操作    c           创建新窗口
                    &           关闭当前窗口
                    数字键      切换至指定窗口
                    p           切换至上一窗口
                    n           切换至下一窗口
                    l           在前后两个窗口间互相切换
                    w           通过窗口列表切换窗口
                    ,           重命名当前窗口；这样便于识别
                    .           修改当前窗口编号；相当于窗口重新排序
                    f           在所有窗口中查找指定文本
                    z           最大化当前窗口 / 恢复窗口
        面板操作    ”           将当前面板平分为上下两块
                    %           将当前面板平分为左右两块
                    x           关闭当前面板
                    !           将当前面板置于新窗口；即新建一个窗口，其中仅包含当前面板
                    Ctrl+方向键 以1个单元格为单位移动边缘以调整当前面板大小
                    Alt+方向键  以5个单元格为单位移动边缘以调整当前面板大小
                    Space       在预置的面板布局中循环切换；依次包括even-horizontal、even-vertical、main-horizontal、main-vertical、tiled
                    q           显示面板pane编号
                    o           在当前窗口中选择下一面板
                    方向键      移动光标以选择面板
                    {           向前置换当前面板
                    }           向后置换当前面板
                    Alt+o       逆时针旋转当前窗口的面板
                    Ctrl+o      顺时针旋转当前窗口的面板
<
    我的TMUX快捷键： >
                    ctrl-d      Detach session
                    | -         Split window
                    ctrl-b      Split window
                    > <         Window movement
                    h l j k     Pan movement
                    tab         Pan movement
                    R           Reload ~/.tmux.conf
                    ctrl-v      Capture pane and open with vim
                    m           Toggle mouse mode
                    + -         Zoom pane to full screen, Restore

24. aria2c 下载工具
    下载:
        aria2c url
        aria2c 'xxx.torrnet'
        aria2c '磁力链接'

    恢复下载：
        aria2c -c url

    列出种子内容:
        aria2c -S target.torrent

    下载种子内编号为 1、4、5、6、7 的文件:
        aria2c –select-file=1,4-7 a.torrent

    下载磁力链接的种子文件:
        aria2c --bt-metadata-only=true --bt-save-metadata=true 'magnet:?xtxxxx'

    需要cookies验证(Chrome插件: 'cookie.txt export'):
        aria2c –load-cookies=cookie_file url

    限速下载:
        单个文件最大下载速度： aria2c –max-download-limit=300K
        整体下载最大速度： aria2c –max-overall-download-limit=300k

    其他常用选项:
        -x 最大的链接线程数
        -j 最大下载的文件个数
        -o 重命名下载的文件

25. 批量重命名文件
    perl版本的rename： >
    rename 's/\.txt$/.a/' *  #把当前文件夹下所有后缀是txt的文件替换成后缀是a

26. 常用小工具
    软件开发:
        ldd             Print shared library dependencies (可执行文件，库)
        nm              List symbols in files (库)
        size            Displays the sizes of sections inside binary files
        objdump         Display information from object files
        addr2line       Convert addresses into line number/file name pairs
        strings         Display printable strings in files
        gprof           display call graph profile data
    其他：
        ps              Report process status
        date            Display the current time in the given FORMAT, or set the system date.
        cal             Display a calendar
        hexdump         Display file contents in hexadecimal, decimal, octal, or ascii
        ascii           Prints all aliases of an ASCII character
        md5sum          Print or check MD5 (128-bit) checksums.
        sha1sum         Print or check SHA1 (106-bit) checksums.
        sha256sum       Print or check SHA256 (256-bit) checksums.
        sha512sum       Print or check SHA512 (512-bit) checksums.
        tree            List contents of directories in a tree-like format.
        tty             Print the file name of the terminal connected to standard input.
        type            Indicate how each name would be interpreted if used as a command name.
        whereis         locate the binary, source, and manual page files for a command
        wc              Print newline, word, and byte counts for each FILE
        time            检查命令执行时间
        column          输出个数成列表格：cat /etc/passwd | column -t -s:
        fzf             a command line fuzzy finder

27. X Window System (Cygwin)
    请求的包： >
        xorg-server, xinit，xhost(远程登录时)
<    启动X Window： >
        $ startxwin                  # 启动X Window System，此时系统的状态栏会出现x window的图标
        $ man xwin                   # 查看xwin的帮助
        $ man startxwin              # 查看startxwin的帮助
<    本地控制台连接到本地Xserver： >
        $ export DISPLAY=:Num.0      # export DISPLAY=:0.0，Num指当前连接的server (如：/tmp/.X11-unix/X0，/tmp/.X11-unix/X1，...)
<    通过ssh远程访问Xserver：(ssh登录后执行如下) >
        $ export DISPLAY=Host:Num.0  # export DISPLAY=172.25.151.1:0.0，Host指client的主机名或者IP地址
        $ xhost +                    # 任何Host都可以显示图形了


28. 包管理 apt / dpkg
    apt-get:
        sudo apt-get install package                安装包
        sudo apt-get install package --reinstall    重新安装包  
        sudo apt-get -f install                     修复安装"-f = ——fix-missing"  
        sudo apt-get remove package                 删除包  
        sudo apt-get remove package --purge         删除包，包括删除配置文件等  
        sudo apt-get autoremove package             删除包及其依赖的软件包  
        sudo apt-get update                         更新源  
        sudo apt-get upgrade                        更新已安装的包  
        sudo apt-get dist-upgrade                   升级系统  
        sudo apt-get dselect-upgrade                使用 dselect 升级  
        sudo apt-get build-dep package              安装相关的编译环境  
        sudo apt-get source package                 下载该包的源代码  
        sudo apt-get clean && sudo apt-get autoclean 清理无用的包  
        sudo apt-get check                          检查是否有损坏的依赖  

    apt-cache (用于搜索包)：
        sudo apt-cache search package               搜索包  
        sudo apt-cache show package                 获取包的相关信息，如说明、大小、版本等  
        sudo apt-cache showpkg package              显示软件包信息，包括包的依赖关系，包的提供者，   
        sudo apt-cache pkgnames                     打印软件包列表中所有包的名字  
        sudo apt-cache dumpavail                    打印软件包列表中所有包的简介信息  
        sudo apt-cache depends package              了解使用依赖  
        sudo apt-cache rdepends package             是查看该包被哪些包依赖

    dpkg (安装离线下载的软件包 *.deb)
        dpkg –l | grep package 查询deb包的详细信息，没有指定包则显示全部已安装包  
        dpkg -s package 查看已经安装的指定软件包的详细信息  
        dpkg -L package 列出一个包安装的所有文件清单  
        dpkg -S file 查看系统中的某个文件属于哪个软件包  
        dpkg -i 所有deb文件的安装  
        dpkg -r 所有deb文件的卸载  
        dpkg -P 彻底的卸载，包括软件的配置文件  
        dpkg -c 查询deb包文件中所包含的文件  
        dpkg -L 查看系统中安装包的的详细清单，同时执行 -c

29. Cygwin上添加新用户 (like Linux 'adduser'):
    $ net user NewUserName NewUserPassword /add /yes        # add user
    $ net localgroup <an_local_group> NewUserName /add      # add user with group
    $ passwd NewUserName                                    # change user password
    $ mkpasswd -l -u NewUserName >> /etc/passwd              # add it to etc

30. Linux搭建git服务器
    创建git用户
        adduser git
    创建证书登录:
        收集所有需要登录的用户的公钥，就是他们自己的id_rsa.pub文件，
        把所有公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。
    创建git库
        sudo git init --bare sample.git
        sudo chown -R git:git sample.git
    禁用shell登录
        修改/etc/passwd的git用户的shell为/usr/bin/git-shell
    客户端clone:
        git clone git@serverIP:/gitsrv/sample.git

31. 启动cygserver,以优化系统性能
    管理员身份运行：
    $ cygserver-config
    $ cygrunsrv -S cygserver

32. 源码编译时 安装文件到指定路径
    make install DESTDIR=/install/directory

33. ss/ssr/v2ray/socks5 透明代理 [https://www.zfl9.com/ss-redir.html]

    先说 ss/ssr 透明代理吧，ss-redir 是 ss-libev[https://github.com/shadowsocks/shadowsocks-libev]、
    ssr-libev[https://github.com/shadowsocksr-backup/shadowsocksr-libev] 中的一个工具，配合 iptables
    可以在 Linux 上实现 ss、ssr 透明代理，ss-redir 的 TCP 透明代理是通过 REDIRECT 方式实现的，而 UDP
    透明代理是通过 TPROXY 方式实现的。强调一点，利用 ss-redir 实现透明代理必须使用 ss-libev 或
    ssr-libev，python、go 等版本没有 ss-redir、ss-tunnel 程序。

    当然，ss、ssr 透明代理并不是只能用 ss-redir 来实现，使用 ss-local + redsocks2/tun2socks 同样可以
    实现 socks5（ss-local 是 socks5 服务器）全局透明代理；ss-local + redsocks2 实际上是 ss-redir
    的分体实现，TCP 使用 REDIRECT 方式，UDP 使用 TPROXY 方式；ss-local + tun2socks 则相当于 Android
    版 SS/SSR 的 VPN 模式，因为它实际上是通过一张虚拟的 tun 网卡来进行代理的。

    最后说一下 v2ray 的透明代理，其实原理和 ss/ssr-libev 一样，v2ray 可以看作是 ss-local、ss-redir、
    ss-tunnel、ss-server 四者的合体，因为同一个 v2ray 程序既可以作为 server 端，也可以作为 client 端。
    所以 v2ray 的透明代理也有两种实现方式，一是利用对应的 ss-redir/ss-tunnel + iptables，二是利用对应的
    ss-local + redsocks2/tun2socks（redsocks2/tun2socks 可以与任意 socks5 代理组合，实现透明代理）。

    组件区别
    ss-server
    shadowsocks 服务端程序，核心部件之一，各大版本均提供 ss-server 程序。

    ss-local
    shadowsocks 客户端程序，核心部件之一，各大版本均提供 ss-local 程序。
    ss-local 是运行在本地的 socks5 代理服务器，根据 OSI 模型，socks5 是会话层协议，支持 TCP 和 UDP 的代理。

    但是现在只有少数软件直接支持 socks5 代理协议，绝大多数都只支持 http 代理协议。好在我们可以利用 privoxy
    将 socks5 代理转换为 http 代理，使用 privoxy 还有一个好处，那就是可以实现 gfwlist 分流模式（不过现在的
    ss-tproxy 脚本也可以了），如果你对它感兴趣，可以看看 ss-local 终端代理[https://www.zfl9.com/ss-local.html]。

    ss-redir
    shadowsocks-libev 提供的socks5 透明代理工具，也就是今天这篇文章的主题 - 实现透明代理！

    正向代理
    正向代理，即平常我们所说的代理，比如 http 代理、socks5 代理等，都属于正向代理。
    正向代理的特点就是：如果需要使用正向代理访问互联网，就必须在客户端进行相应的代理设置。

    透明代理
    透明代理和正向代理的作用是一样的，都是为了突破某些网络限制，访问网络资源。
    但是透明代理对于客户端是透明的，客户端不需要进行相应的代理设置，就能使用透明代理访问互联网。

    反向代理
    当然，这个不在本文的讨论范畴之内，不过既然提到了前两种代理，就顺便说说反向代理。
    反向代理是针对服务端来说的，它的目的不是为了让我们突破互联网限制，而是为了实现负载均衡。

    举个栗子：
    ss-local 提供 socks5 正向代理，要让软件使用该代理，必须对软件进行相应的代理配置，否则不会走代理；
    ss-redir 提供 socks5 透明代理，配置合适网络规则后，软件会在不知情的情况下走代理，不需要额外配置。

    ss-tunnel
    shadowsocks-libev 提供的本地端口转发工具，通常用于解决 dns 污染问题。

    假设 ss-tunnel 监听本地端口 53，转发的远程目的地为 8.8.8.8:53；系统 dns 为 127.0.0.1。
    去程：上层应用请求 dns 解析 -> ss-tunnel 接收 -> ss 隧道 -> ss-server 接收 -> 8.8.8.8:53；
    回程：8.8.8.8:53 响应 dns 请求 -> ss-server 接收 -> ss 隧道 -> ss-tunnel 接收 -> 上层应用。

    方案说明
    用过 Linux SS/SSR 客户端（尤其指命令行界面）的都知道，它们比 Windows/Android 中的 SS/SSR 客户端难用多了，
    安装好就只有一个 ss-local（libev 版还有 ss-redir、ss-tunnel，但我相信大部分人装得都是 python 版的），
    启动 ss-local 后并不会像 Windows/Android 那样自动配置系统代理，此时它仅仅是一个本地 socks5 代理服务器，
    默认监听 127.0.0.1:1080，如果需要利用该 socks5 代理上外网，必须在命令中指定对应的代理，
    如 curl -4sSkL -x socks5h://127.0.0.1:1080 https://www.google.com。

    但我想大部分人要的代理效果都不是这种的，太原始了。那能不能配置所谓的“系统代理”呢，可以是可以，
    但是好像只支持 http 类型的代理，即在当前 shell 中设置 http_proxy、https_proxy 环境变量，假设存在
    一个 http 代理（支持 CONNECT 请求方法），监听地址是 127.0.0.1:8118，可以这样做：
    export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy。执行完后，git、curl、wget
    等命令会自动从环境变量中读取 http 代理信息，然后通过 http 代理连接目的服务器。

    那问题来了，ss-local 提供的是 socks5 代理，不能直接使用怎么办？也简单，Linux 中有很多将 socks5 包装为
    http 代理的工具，比如 privoxy。只需要在 /etc/privoxy/config 里面添加一行 forward-socks5 / 127.0.0.1:1080 .，
    启动 privoxy，默认监听 127.0.0.1:8118 端口，注意别搞混了，8118 是 privoxy 提供的 http 代理地址，
    而 1080 是 ss-local 提供的 socks5 代理地址，发往 8118 端口的数据会被 privoxy 处理并转发给 ss-local。
    所以我们现在可以执行 export http_proxy=http://127.0.0.1:8118; export https_proxy=$http_proxy 来配置
    当前终端的 http 代理，这样 git、curl、wget 这些就会自动走 ss-local 出去了。

    当然我们还可以利用 privoxy 灵活的配置，实现 Windows/Android 中的 gfwlist 分流模式。gfwlist.txt 其实是
    对应的 Adblock Plus 规则的 base64 编码文件，显然不能直接照搬到 privoxy 上。这个问题其实已经有人解决了，
    利用 snachx/gfwlist2privoxy python 脚本就可轻松搞定。但其实我也重复的造了一个轮子：zfl9/gfwlist2privoxy，
    我并不是吃饱了没事干，是因为我当时运行不了他的脚本（也不知道什么原因），所以花了点时间用 shell 脚本实现
    了一个 gfwlist2privoxy（但其实我是用 perl 转换的，只不过用 shell 包装了一下）。脚本转换出来的是一个
    gfwlist.action 文件，我们只需将该 gfwlist.action 文件放到 /etc/privoxy 目录，然后在 config 中添加一行
    actionsfile gfwlist.action（当然之前 forward-socks5 那行要注释掉），重启 privoxy 就可以实现 gfwlist 分流了。

    但仅仅依靠 http_proxy、https_proxy 环境变量实现的终端代理效果不是很好，因为有些命令根本不理会你的
    http_proxy、https_proxy 变量，它们依旧走的直连。但又有大神想出了一个巧妙的方法，即 rofl0r/proxychains-ng，
    其原理是通过 LD_PRELOAD 特殊环境变量提前加载指定的动态库，来替换 glibc 中的同名库函数。这个 LD_PRELOAD
    指向的其实就是 proxychains-ng 实现的 socket 包装库，这个包装库会读取 proxychains-ng 的配置文件（这里面配
    置代理信息），之后执行的所有命令调用的 socket 函数其实都是 proxychains-ng 动态库中的同名函数，于是就实现
    了全局代理，而命令对此一无所知。将 proxychains-ng 与 privoxy 结合起来基本上可以完美实现 ss/ssr 的本地全局
    gfwlist代理（小技巧，在 shell 中执行 exec proxychains -q bash 可以实现当前终端的全局代理，如果需要每个终端
    都自动全局代理，可以在 bashrc 文件中加入这行）。

    但是很多人对此依然无法满足，因为他们想实现 OpenWrt 那种路由级别的全局透明代理（并且还有 gfwlist、绕过大陆
    地址段这些分流模式可选择），这样只要设备连到 WiFi 就能直接无缝上网，完全感觉不到“墙”的存在。如果忽略分流
    模式（即全部流量都走代理出去），那么实现是很简单的（几条 iptables 就可以搞定，但是这太简单粗暴了，很多国
    内网站走代理会非常慢，体验很不好）；但是如果要自己实现 gfwlist、绕过大陆地址段这些模式，恐怕很多人都会望
    而却步，因为确实复杂了一些。但这种透明代理的模式的确很诱人，毕竟只要设置一次就可以让所有内网设备上 Internet，
    所以我开始摸索如何在 Linux 软路由中（我用的是树莓派 3B，目前还凑合，当然也可以直接在 Windows 中利用 
    VMware/VirtualBox 建一个桥接模式的虚拟机，做所谓的 代理网关）实现类似 OpenWrt 的代理模式，而我摸索出来的
    成果就是 ss-tproxy 透明代理脚本。

    ShadowsocksR
    ShadowsocksR（简称 SSR）是由 @breakwa11 发起的一个 Shadowsocks 分支，主要特点是增加了协议插件（增强安全性）
    和混淆插件（降低识别率），虽然 breakwa11 早在 2017 年 7 月就已经删除了 SSR 相关源码，但我目前仍然使用的 SSR
    （V2Ray 速度不行，我的树莓派 3B 完全带不起），自写了一个 C 语言版的 v2ray，即 tls-proxy，用在树莓派上完全没
    问题，速度与 ss/ssr-libev 基本没区别。因为原版 SS 被 QoS（Quality of Service，服务质量）影响严重
    （SS + simple-obfs 也能像 SSR 那样混淆），如果不将流量伪装为 HTTP/HTTPS 数据，那么代理的速度很难提上来
    （即使装了锐速、BBR 魔改）。为什么呢，因为 HTTP/HTTPS 流量的优先级相对来说是比较高的（标准端口，HTTP/80、HTTPS/443），
    优先级高的包在国际出口上就会先发送，尽量不滞留，路顺畅了速度自然就上来了。

    SSR 混淆说明
    ## Client -> Server 方向
    客户端请求 -> ss-local -> 协议插件 -> 加密 -> 混淆插件
    x======================== GFW =======================
    混淆插件 -> 解密 -> 协议插件 -> ss-server -> 目标服务器
    ## 协议插件与混淆插件的作用
    "协议插件": 主要用于增加数据完整性校验，增强安全性，进行包长度混淆等
    "混淆插件": 主要用于伪装为其它协议（如 HTTP、HTTPS），扰乱 GFW 的检测
    ## 推荐的协议插件与混淆插件
    协议插件: "auth_sha1_v4"、"auth_aes128_md5"、"auth_aes128_sha1"、"auth_chain_a"
    混淆插件: "plain"（即：不混淆）、"http_simple"、"http_post"、"tls1.2_ticket_auth"
    # 为什么推荐 plain，因为混淆不总是有效果的，有时候不混淆让其看起来像随机数据会更好一些


vim:ft=help
